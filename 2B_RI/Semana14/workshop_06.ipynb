{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Taller 06: Bases de Datos Vectoriales**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Integrantes:**\n",
    "- Calahorrano David\n",
    "- Códorva Carlos\n",
    "- Zambrano Ándres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objetivo:**\n",
    "En este ejercicio implementarás un sistema de recuperación que utilice representaciones vectoriales de texto y compararás este enfoque con los modelos TF-IDF y BM25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Requisitos:**\n",
    "1. Librerías Python necesarias: sentence-transformers, FAISS, ChromaDB.\n",
    "2. Instalar Elasticsearch en un contenedor utilizando Docker.\n",
    "3. Dataset Wikipedia Movie Plots, disponible en Kaggle, y utilizado en el taller 05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conceptos Clave**\n",
    "#### **TF-IDF**\n",
    "- **Definición:** TF-IDF (Term Frequency - Inverse Document Frequency) es una métrica que mide la relevancia de un término dentro de un documento respecto a un corpus. Combina dos factores:\n",
    "- **Frecuencia del término (TF):** Qué tan frecuente es una palabra en un documento.\n",
    "- **Frecuencia inversa en el corpus (IDF):** Penaliza palabras comunes en el corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **BM25**\n",
    "- **Definición:** Una extensión de TF-IDF que ajusta la relevancia basada en:\n",
    "  - La longitud del documento (normalización).\n",
    "  - La saturación de la frecuencia del término (evita que palabras muy repetidas dominen el puntaje).\n",
    "- **Ventajas:** Proporciona una búsqueda de texto más precisa y es el método predeterminado en Elasticsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Embeddings**\n",
    "- **Definición:** Representaciones vectoriales de texto que capturan relaciones semánticas entre palabras o frases. Los embeddings transforman palabras o documentos en vectores en un espacio multidimensional donde textos similares están cerca entre sí.\n",
    "- **Herramienta:** Librería sentence-transformers, que ofrece modelos preentrenados como all-MiniLM-L6-v2 para generar embeddings de alta calidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bases de Datos Vectoriales (FAISS y ChromaDB)**\n",
    "- **FAISS:** Biblioteca especializada en búsquedas rápidas en grandes colecciones de vectores. Diseñada para escalabilidad y velocidad.\n",
    "- **ChromaDB:** Base de datos orientada a embeddings que ofrece funcionalidades avanzadas para almacenar y consultar vectores de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comparación de Estrategias de Recuperación**\n",
    "- **TF-IDF vs. BM25 vs. Embeddings:**\n",
    "  - **TF-IDF:** Mide la relevancia de palabras clave basándose en su frecuencia relativa.\n",
    "  - **BM25:** Mejora TF-IDF ajustando por la longitud del documento y saturación de términos.\n",
    "  - **Embeddings:** Capturan relaciones semánticas, permitiendo recuperar documentos relevantes, aunque las palabras exactas no coincidan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preparación del Dataset: Wikipedia Movie Plots**\n",
    "1. Usa el dataset del Taller 05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Instrucciones**\n",
    "#### **Parte 1: Recuperación con TF-IDF**\n",
    "1. Cargar los datos en Python\n",
    "2. Configurar TF-IDF:\n",
    "   - Usa la librería scikit-learn para calcular los puntajes TF-IDF de los plots.\n",
    "3. Realizar consultas:\n",
    "   - Escribe una función que calcule la similitud entre una consulta y los documentos usando la matriz TF-IDF.\n",
    "4. Evaluar los resultados:\n",
    "   - Registra los documentos recuperados y analiza su relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 2: Recuperación con BM25**\n",
    "1. Configurar Elasticsearch:\n",
    "   - Reutiliza el índice creado en el Ejercicio 1 para realizar consultas basadas en BM25.\n",
    "2. Realizar consultas:\n",
    "   - Usa palabras clave como \"dinosaurs\" o \"cyborg\" para encontrar documentos relevantes.\n",
    "3. Evaluar los resultados:\n",
    "   - Compara los documentos recuperados con los obtenidos usando TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 3: Recuperación con FAISS**\n",
    "1. Configurar FAISS:\n",
    "   - Crea un índice en FAISS y agrega los embeddings generados previamente.\n",
    "2. Realizar consultas:\n",
    " - Convierte una consulta en texto (e.g., \"A park with cloned dinosaurs\") en un vector usando el mismo modelo de embeddings.\n",
    " - Busca los vectores más cercanos en FAISS.\n",
    "3. Evaluar los resultados:\n",
    "- Compara los documentos recuperados por FAISS con los obtenidos usando TF-IDF y BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 4: Recuperación con ChromaDB**\n",
    "1. Configurar ChromaDB:\n",
    "- Inicia una base de datos de ChromaDB y define el esquema con los campos Title, Plot y Embedding.\n",
    "2. Insertar documentos y embeddings:\n",
    "- Agrega los documentos y sus embeddings generados previamente a ChromaDB, junto con los metadatos correspondientes (e.g., título y trama).\n",
    "3. Realizar consultas:\n",
    "- Convierte una consulta de texto en un embedding.\n",
    "- Busca los vectores más cercanos en ChromaDB y recupera los documentos relacionados.\n",
    "4. Evaluar los resultados:\n",
    "- Compara los documentos recuperados por ChromaDB con los de FAISS, TF-IDF y BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 5: Comparación de Resultados**\n",
    "1. Relevancia:\n",
    "   - Analiza cuál de las estrategias (TF-IDF, BM25, FAISS o ChromaDB) recupera documentos más relevantes para diferentes consultas.\n",
    "2. Ventajas y limitaciones:\n",
    "   - Reflexiona sobre los puntos fuertes y débiles de cada enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
