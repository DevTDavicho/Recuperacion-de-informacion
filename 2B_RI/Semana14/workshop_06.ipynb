{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Taller 06: Bases de Datos Vectoriales**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Integrantes:**\n",
    "- Calahorrano David\n",
    "- Códorva Carlos\n",
    "- Zambrano Ándres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objetivo:**\n",
    "En este ejercicio implementarás un sistema de recuperación que utilice representaciones vectoriales de texto y compararás este enfoque con los modelos TF-IDF y BM25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Requisitos:**\n",
    "1. Librerías Python necesarias: sentence-transformers, FAISS, ChromaDB.\n",
    "2. Instalar Elasticsearch en un contenedor utilizando Docker.\n",
    "3. Dataset Wikipedia Movie Plots, disponible en Kaggle, y utilizado en el taller 05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conceptos Clave**\n",
    "#### **TF-IDF**\n",
    "- **Definición:** TF-IDF (Term Frequency - Inverse Document Frequency) es una métrica que mide la relevancia de un término dentro de un documento respecto a un corpus. Combina dos factores:\n",
    "- **Frecuencia del término (TF):** Qué tan frecuente es una palabra en un documento.\n",
    "- **Frecuencia inversa en el corpus (IDF):** Penaliza palabras comunes en el corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **BM25**\n",
    "- **Definición:** Una extensión de TF-IDF que ajusta la relevancia basada en:\n",
    "  - La longitud del documento (normalización).\n",
    "  - La saturación de la frecuencia del término (evita que palabras muy repetidas dominen el puntaje).\n",
    "- **Ventajas:** Proporciona una búsqueda de texto más precisa y es el método predeterminado en Elasticsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Embeddings**\n",
    "- **Definición:** Representaciones vectoriales de texto que capturan relaciones semánticas entre palabras o frases. Los embeddings transforman palabras o documentos en vectores en un espacio multidimensional donde textos similares están cerca entre sí.\n",
    "- **Herramienta:** Librería sentence-transformers, que ofrece modelos preentrenados como all-MiniLM-L6-v2 para generar embeddings de alta calidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bases de Datos Vectoriales (FAISS y ChromaDB)**\n",
    "- **FAISS:** Biblioteca especializada en búsquedas rápidas en grandes colecciones de vectores. Diseñada para escalabilidad y velocidad.\n",
    "- **ChromaDB:** Base de datos orientada a embeddings que ofrece funcionalidades avanzadas para almacenar y consultar vectores de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comparación de Estrategias de Recuperación**\n",
    "- **TF-IDF vs. BM25 vs. Embeddings:**\n",
    "  - **TF-IDF:** Mide la relevancia de palabras clave basándose en su frecuencia relativa.\n",
    "  - **BM25:** Mejora TF-IDF ajustando por la longitud del documento y saturación de términos.\n",
    "  - **Embeddings:** Capturan relaciones semánticas, permitiendo recuperar documentos relevantes, aunque las palabras exactas no coincidan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preparación del Dataset: Wikipedia Movie Plots**\n",
    "1. Usa el dataset del Taller 05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Cargar el dataset utilizado en el taller 05\n",
    "file_path = r'C:\\Users\\USER\\.cache\\kagglehub\\datasets\\jrobischon\\wikipedia-movie-plots\\versions\\1\\wiki_movie_plots_deduped.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "data = df[['Title', 'Plot']].head(36000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Playing Around</td>\n",
       "      <td>Alice White plays the part of a working class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Raffles</td>\n",
       "      <td>Gentleman jewel thief A.J. Raffles (Ronald Col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Reaching for the Moon</td>\n",
       "      <td>Wall Street wizard, Larry Day, new to the ways...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Recaptured Love</td>\n",
       "      <td>In this drama, a 50-year-old married man (play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>River's End</td>\n",
       "      <td>In remote northern Canada, Sergeant Conniston ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title  \\\n",
       "0              Kansas Saloon Smashers   \n",
       "1       Love by the Light of the Moon   \n",
       "2             The Martyred Presidents   \n",
       "3    Terrible Teddy, the Grizzly King   \n",
       "4              Jack and the Beanstalk   \n",
       "..                                ...   \n",
       "995                    Playing Around   \n",
       "996                           Raffles   \n",
       "997             Reaching for the Moon   \n",
       "998                   Recaptured Love   \n",
       "999                       River's End   \n",
       "\n",
       "                                                  Plot  \n",
       "0    A bartender is working at a saloon, serving dr...  \n",
       "1    The moon, painted with a smiling face hangs ov...  \n",
       "2    The film, just over a minute long, is composed...  \n",
       "3    Lasting just 61 seconds and consisting of two ...  \n",
       "4    The earliest known adaptation of the classic f...  \n",
       "..                                                 ...  \n",
       "995  Alice White plays the part of a working class ...  \n",
       "996  Gentleman jewel thief A.J. Raffles (Ronald Col...  \n",
       "997  Wall Street wizard, Larry Day, new to the ways...  \n",
       "998  In this drama, a 50-year-old married man (play...  \n",
       "999  In remote northern Canada, Sergeant Conniston ...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  # Minúsculas\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Eliminar puntuaciones\n",
    "    text = re.sub(r'\\d+', '', text)     # Eliminar números\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Espacios adicionales\n",
    "    \n",
    "    # Eliminar palabras repetidas\n",
    "    palabras = text.split()\n",
    "    palabras_unicas = []\n",
    "    for palabra in palabras:\n",
    "        if palabra not in palabras_unicas:\n",
    "            palabras_unicas.append(palabra)\n",
    "    return ' '.join(palabras_unicas)\n",
    "\n",
    "# Normalizar tramas\n",
    "data['Normalized Plot'] = data['Plot'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Instrucciones**\n",
    "#### **Parte 1: Recuperación con TF-IDF**\n",
    "1. Cargar los datos en Python\n",
    "2. Configurar TF-IDF:\n",
    "   - Usa la librería scikit-learn para calcular los puntajes TF-IDF de los plots.\n",
    "3. Realizar consultas:\n",
    "   - Escribe una función que calcule la similitud entre una consulta y los documentos usando la matriz TF-IDF.\n",
    "4. Evaluar los resultados:\n",
    "   - Registra los documentos recuperados y analiza su relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados con TF-IDF:\n",
      "33572     Yona Yona Penguin\n",
      "7771                Rampage\n",
      "649       The Love of Sunya\n",
      "17507             Crosstalk\n",
      "3799              Girl Rush\n",
      "10773          Mr. Nice Guy\n",
      "18620    The Night Has Eyes\n",
      "29474         Kurathi Magan\n",
      "29310                Bommai\n",
      "22010               XChange\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(data['Normalized Plot'])\n",
    "\n",
    "# Consulta con TF-IDF\n",
    "query = \"time travel future\"\n",
    "query_vec = vectorizer.transform([normalize_text(query)])\n",
    "\n",
    "# Calcular similitud de coseno\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(query_vec, X_tfidf).flatten()\n",
    "\n",
    "# Obtener los resultados más relevantes\n",
    "results_tfidf = data.iloc[cos_sim.argsort()[-10:][::-1]]['Title']\n",
    "print(\"Resultados con TF-IDF:\")\n",
    "print(results_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 2: Recuperación con BM25**\n",
    "1. Configurar Elasticsearch:\n",
    "   - Reutiliza el índice creado en el Ejercicio 1 para realizar consultas basadas en BM25.\n",
    "2. Realizar consultas:\n",
    "   - Usa palabras clave como \"dinosaurs\" o \"cyborg\" para encontrar documentos relevantes.\n",
    "3. Evaluar los resultados:\n",
    "   - Compara los documentos recuperados con los obtenidos usando TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado a Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Crear la conexión\n",
    "es = Elasticsearch(['http://localhost:9200'])  # Se incluye el esquema http\n",
    "index_name = 'movies'\n",
    "\n",
    "# Verificar la conexión\n",
    "if es.ping():\n",
    "    print(\"Conectado a Elasticsearch\")\n",
    "else:\n",
    "    print(\"Error al conectar con Elasticsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear índice\n",
    "def crear_indice_elasticsearch():\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        es.indices.create(index=index_name, body={\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"title\": {\"type\": \"text\"},\n",
    "                    \"plot\": {\"type\": \"text\"}\n",
    "                }\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "# Indexar documentos\n",
    "def indexar_documentos(data):\n",
    "    actions = []\n",
    "    for _, row in data.iterrows():\n",
    "        actions.append({\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": {\n",
    "                \"title\": row['Title'],\n",
    "                \"plot\": row['Normalized Plot']\n",
    "            }\n",
    "        })\n",
    "    bulk(es, actions)\n",
    "\n",
    "crear_indice_elasticsearch()\n",
    "indexar_documentos(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_bm25_elasticsearch(consulta):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"plot\": consulta\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    resultados = es.search(index=index_name, body=query, size=10)\n",
    "    for hit in resultados['hits']['hits']:\n",
    "        print(hit['_source']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados con BM25 para la consulta 'dinosaurs':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20804\\268924553.py:9: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  resultados = es.search(index=index_name, body=query, size=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theodore Rex\n",
      "Theodore Rex\n",
      "Theodore Rex\n",
      "Two Lost Worlds\n",
      "Two Lost Worlds\n",
      "Two Lost Worlds\n",
      "The Lost World\n",
      "Magic Tree House\n",
      "The Lost World\n",
      "Magic Tree House\n"
     ]
    }
   ],
   "source": [
    "# Realizar consultas\n",
    "consulta_bm25 = \"dinosaurs\"\n",
    "print(\"Resultados con BM25 para la consulta 'dinosaurs':\")\n",
    "buscar_bm25_elasticsearch(consulta_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados con BM25 para la consulta 'cyborg':\n",
      "Cyborg 3: The Recycler\n",
      "Future X-Cops\n",
      "Cyborg 3: The Recycler\n",
      "Future X-Cops\n",
      "Cyborg 3: The Recycler\n",
      "Future X-Cops\n",
      "Sun Vulcan Movie\n",
      "964 Pinocchio\n",
      "Sun Vulcan Movie\n",
      "964 Pinocchio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_20804\\268924553.py:9: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  resultados = es.search(index=index_name, body=query, size=10)\n"
     ]
    }
   ],
   "source": [
    "consulta_bm25_2 = \"cyborg\"\n",
    "print(\"Resultados con BM25 para la consulta 'cyborg':\")\n",
    "buscar_bm25_elasticsearch(consulta_bm25_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 3: Recuperación con FAISS**\n",
    "1. Configurar FAISS:\n",
    "   - Crea un índice en FAISS y agrega los embeddings generados previamente.\n",
    "2. Realizar consultas:\n",
    "   - Convierte una consulta en texto (e.g., \"A park with cloned dinosaurs\") en un vector usando el mismo modelo de embeddings.\n",
    "   - Busca los vectores más cercanos en FAISS.\n",
    "3. Evaluar los resultados:\n",
    "   - Compara los documentos recuperados por FAISS con los obtenidos usando TF-IDF y BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Configurar el modelo\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generar embeddings para cada trama normalizada\n",
    "data['Embeddings'] = data['Normalized Plot'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Crear un índice en FAISS\n",
    "dimension = len(data['Embeddings'][0])  # Dimensión de los embeddings\n",
    "index = faiss.IndexFlatL2(dimension)   # Índice de FAISS usando L2 (distancia euclidiana)\n",
    "\n",
    "# Convertir los embeddings en una matriz numpy y añadirlos al índice\n",
    "embeddings_matrix = np.array(data['Embeddings'].tolist())\n",
    "index.add(embeddings_matrix)\n",
    "print(\"Embeddings indexados en FAISS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar modelo de prueba\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Modelo cargado correctamente.\")\n",
    "\n",
    "# Probar generación de embeddings\n",
    "query = \"A park with cloned dinosaurs\"\n",
    "query_embedding = model.encode(query)\n",
    "print(\"Primeros 5 valores del embedding:\", query_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Configurar FAISS y generar embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "data['Embeddings'] = data['Normalized Plot'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Crear el índice de FAISS\n",
    "dimension = len(data['Embeddings'][0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Convertir embeddings a formato numpy y añadirlos al índice\n",
    "embeddings_matrix = data['Embeddings'].tolist()\n",
    "index.add(np.array(embeddings_matrix))\n",
    "\n",
    "# Realizar consultas\n",
    "query_text = \"A park with cloned dinosaurs\"\n",
    "query_embedding = model.encode(query_text)\n",
    "\n",
    "# Buscar los vectores más cercanos\n",
    "k = 10  # Número de resultados\n",
    "distances, indices = index.search(np.array([query_embedding]), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 4: Recuperación con ChromaDB**\n",
    "1. Configurar ChromaDB:\n",
    "   - Inicia una base de datos de ChromaDB y define el esquema con los campos Title, Plot y Embedding.\n",
    "2. Insertar documentos y embeddings:\n",
    "   - Agrega los documentos y sus embeddings generados previamente a ChromaDB, junto con los metadatos correspondientes (e.g., título y trama).\n",
    "3. Realizar consultas:\n",
    "   - Convierte una consulta de texto en un embedding.\n",
    "   - Busca los vectores más cercanos en ChromaDB y recupera los documentos relacionados.\n",
    "4. Evaluar los resultados:\n",
    "   - Compara los documentos recuperados por ChromaDB con los de FAISS, TF-IDF y BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 5: Comparación de Resultados**\n",
    "1. Relevancia:\n",
    "   - Analiza cuál de las estrategias (TF-IDF, BM25, FAISS o ChromaDB) recupera documentos más relevantes para diferentes consultas.\n",
    "2. Ventajas y limitaciones:\n",
    "   - Reflexiona sobre los puntos fuertes y débiles de cada enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
